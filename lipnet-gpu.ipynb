{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:02.699677Z",
     "iopub.status.busy": "2024-12-12T06:46:02.698602Z",
     "iopub.status.idle": "2024-12-12T06:46:14.770635Z",
     "shell.execute_reply": "2024-12-12T06:46:14.769501Z",
     "shell.execute_reply.started": "2024-12-12T06:46:02.699601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.3-cp310-cp310-win_amd64.whl (7.8 MB)\n",
      "Collecting imageio\n",
      "  Using cached imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Collecting tensorflow==2.16.1\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Downloading tensorflow_intel-2.16.1-cp310-cp310-win_amd64.whl (376.9 MB)\n",
      "     -------------------------------------- 376.9/376.9 MB 5.0 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\noobs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\noobs\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (1.16.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-win_amd64.whl (127 kB)\n",
      "     -------------------------------------- 127.8/127.8 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.17.0-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.68.1-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.12.1-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting keras>=3.0.0\n",
      "  Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\noobs\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (4.12.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\noobs\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (24.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\noobs\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.3-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 7.4 MB/s eta 0:00:00\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "     -------------------------------------- 147.9/147.9 kB 8.6 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\noobs\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.13.1-cp310-cp310-win_amd64.whl (282 kB)\n",
      "     -------------------------------------- 282.7/282.7 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\noobs\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.18.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, tqdm, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, soupsieve, PySocks, pyparsing, protobuf, pillow, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, idna, grpcio, google-pasta, gast, fonttools, filelock, cycler, charset-normalizer, certifi, absl-py, werkzeug, requests, opencv-python, ml-dtypes, markdown-it-py, imageio, h5py, contourpy, beautifulsoup4, astunparse, tensorboard, rich, matplotlib, keras, gdown, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 PySocks-1.7.1 absl-py-2.1.0 astunparse-1.6.3 beautifulsoup4-4.12.3 certifi-2024.8.30 charset-normalizer-3.4.0 contourpy-1.3.1 cycler-0.12.1 filelock-3.16.1 flatbuffers-24.3.25 fonttools-4.55.3 gast-0.6.0 gdown-5.2.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 idna-3.10 imageio-2.36.1 keras-3.7.0 kiwisolver-1.4.7 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.9.3 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 numpy-1.26.4 opencv-python-4.10.0.84 opt-einsum-3.4.0 optree-0.13.1 pillow-11.0.0 protobuf-4.25.5 pyparsing-3.2.0 requests-2.32.3 rich-13.9.4 soupsieve-2.6 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 tqdm-4.67.1 urllib3-2.2.3 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python matplotlib imageio gdown tensorflow==2.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.16.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\noobs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# !pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:18.103828Z",
     "iopub.status.busy": "2024-12-12T06:46:18.103346Z",
     "iopub.status.idle": "2024-12-12T06:46:18.379826Z",
     "shell.execute_reply": "2024-12-12T06:46:18.378701Z",
     "shell.execute_reply.started": "2024-12-12T06:46:18.103786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:20.642699Z",
     "iopub.status.busy": "2024-12-12T06:46:20.641273Z",
     "iopub.status.idle": "2024-12-12T06:46:20.650894Z",
     "shell.execute_reply": "2024-12-12T06:46:20.649430Z",
     "shell.execute_reply.started": "2024-12-12T06:46:20.642660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure GPU memory growth\n",
    "physical_device = tf.config.list_physical_devices('GPU')\n",
    "if physical_device:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_device[0], True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:21.264549Z",
     "iopub.status.busy": "2024-12-12T06:46:21.263567Z",
     "iopub.status.idle": "2024-12-12T06:46:33.052981Z",
     "shell.execute_reply": "2024-12-12T06:46:33.051843Z",
     "shell.execute_reply.started": "2024-12-12T06:46:21.264473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Download data\n",
    "# url = \"https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL\"\n",
    "# output = \"data.zip\"\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall(\"data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.055246Z",
     "iopub.status.busy": "2024-12-12T06:46:33.054889Z",
     "iopub.status.idle": "2024-12-12T06:46:33.116596Z",
     "shell.execute_reply": "2024-12-12T06:46:33.115433Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.055215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary setup\n",
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.118510Z",
     "iopub.status.busy": "2024-12-12T06:46:33.118092Z",
     "iopub.status.idle": "2024-12-12T06:46:33.143288Z",
     "shell.execute_reply": "2024-12-12T06:46:33.141988Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.118457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get((cv2.CAP_PROP_FRAME_COUNT)))):\n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236, 80:220, :])\n",
    "    cap.release()\n",
    "\n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.146160Z",
     "iopub.status.busy": "2024-12-12T06:46:33.145807Z",
     "iopub.status.idle": "2024-12-12T06:46:33.163028Z",
     "shell.execute_reply": "2024-12-12T06:46:33.161994Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.146104Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([22  1  9  2], shape=(4,), dtype=int64)\n",
      "tf.Tensor([b'v' b'a' b'i' b'b'], shape=(4,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(char_to_num(['v','a','i','b']))\n",
    "print(num_to_char([22,  1,  9,  2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.164166Z",
     "iopub.status.busy": "2024-12-12T06:46:33.163906Z",
     "iopub.status.idle": "2024-12-12T06:46:33.169878Z",
     "shell.execute_reply": "2024-12-12T06:46:33.168893Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.164140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]:\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil':\n",
    "            tokens = [*tokens, ' ', line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.171424Z",
     "iopub.status.busy": "2024-12-12T06:46:33.171087Z",
     "iopub.status.idle": "2024-12-12T06:46:33.182988Z",
     "shell.execute_reply": "2024-12-12T06:46:33.181978Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.171394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    # print(f'This is the path: {path}')\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    # Extract the file name without extension\n",
    "    file_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    \n",
    "    # Construct video and alignment paths\n",
    "    video_path = os.path.join('data', 's1', f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data', 'alignments', 's1', f'{file_name}.align')\n",
    "    \n",
    "    # Ensure files exist\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "    if not os.path.exists(alignment_path):\n",
    "        raise FileNotFoundError(f\"Alignment file not found: {alignment_path}\")\n",
    "\n",
    "    # Load video frames and alignments\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.184440Z",
     "iopub.status.busy": "2024-12-12T06:46:33.184158Z",
     "iopub.status.idle": "2024-12-12T06:46:33.199250Z",
     "shell.execute_reply": "2024-12-12T06:46:33.198125Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.184413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.200526Z",
     "iopub.status.busy": "2024-12-12T06:46:33.200211Z",
     "iopub.status.idle": "2024-12-12T06:46:33.317765Z",
     "shell.execute_reply": "2024-12-12T06:46:33.316664Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.200497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # /kaggle/working/data/alignments/s1/bbaf2n.align\n",
    "# /kaggle/working/data/s1/bbaf2n.mpg\n",
    "data = tf.data.Dataset.list_files('data/s1/*.mpg') \n",
    "data = data.shuffle(500)\n",
    "data = data.map(mappable_function) # map the function to the dataset\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None], [40])) # padding to the frames and alignments[40] if less than then padded it \n",
    "\n",
    "# With prefetching, the next batch is prepared asynchronously while the current batch is being used by the model, reducing idle time.\n",
    "# That reduce input latency \n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Added for split \n",
    "train = data.take(450)\n",
    "test = data.skip(450)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.319443Z",
     "iopub.status.busy": "2024-12-12T06:46:33.319116Z",
     "iopub.status.idle": "2024-12-12T06:46:33.326430Z",
     "shell.execute_reply": "2024-12-12T06:46:33.325324Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.319413Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:33.329788Z",
     "iopub.status.busy": "2024-12-12T06:46:33.329445Z",
     "iopub.status.idle": "2024-12-12T06:46:34.362814Z",
     "shell.execute_reply": "2024-12-12T06:46:34.361768Z",
     "shell.execute_reply.started": "2024-12-12T06:46:33.329758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Two videos and two alignments\n",
    "videos, alignments = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:34.364300Z",
     "iopub.status.busy": "2024-12-12T06:46:34.364021Z",
     "iopub.status.idle": "2024-12-12T06:46:34.370595Z",
     "shell.execute_reply": "2024-12-12T06:46:34.369518Z",
     "shell.execute_reply.started": "2024-12-12T06:46:34.364274Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a video shape : (2, 75, 46, 140, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'This is a video shape : {videos.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:34.372086Z",
     "iopub.status.busy": "2024-12-12T06:46:34.371769Z",
     "iopub.status.idle": "2024-12-12T06:46:34.383610Z",
     "shell.execute_reply": "2024-12-12T06:46:34.382549Z",
     "shell.execute_reply.started": "2024-12-12T06:46:34.372057Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videos), len(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:34.385378Z",
     "iopub.status.busy": "2024-12-12T06:46:34.385034Z",
     "iopub.status.idle": "2024-12-12T06:46:35.218787Z",
     "shell.execute_reply": "2024-12-12T06:46:35.217672Z",
     "shell.execute_reply.started": "2024-12-12T06:46:34.385347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = data.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:35.220973Z",
     "iopub.status.busy": "2024-12-12T06:46:35.220498Z",
     "iopub.status.idle": "2024-12-12T06:46:35.535935Z",
     "shell.execute_reply": "2024-12-12T06:46:35.534801Z",
     "shell.execute_reply.started": "2024-12-12T06:46:35.220930Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x227bd8f76a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0: videos; 0: 1st video out of the batch, 0: return the 40th frame in the video\n",
    "plt.imshow(sample[0][1][40])\n",
    "# plt.imshow(videos[0][40]) # both are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:35.537825Z",
     "iopub.status.busy": "2024-12-12T06:46:35.537368Z",
     "iopub.status.idle": "2024-12-12T06:46:35.543166Z",
     "shell.execute_reply": "2024-12-12T06:46:35.542007Z",
     "shell.execute_reply.started": "2024-12-12T06:46:35.537777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " test_path = \"data/s1/bbaf2n.mpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:35.544962Z",
     "iopub.status.busy": "2024-12-12T06:46:35.544598Z",
     "iopub.status.idle": "2024-12-12T06:46:35.922956Z",
     "shell.execute_reply": "2024-12-12T06:46:35.921695Z",
     "shell.execute_reply.started": "2024-12-12T06:46:35.544931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Testing loading function\n",
    "frames, alignments = load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:35.924930Z",
     "iopub.status.busy": "2024-12-12T06:46:35.924451Z",
     "iopub.status.idle": "2024-12-12T06:46:36.052889Z",
     "shell.execute_reply": "2024-12-12T06:46:36.051815Z",
     "shell.execute_reply.started": "2024-12-12T06:46:35.924874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole the frame: (75, 46, 140, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(46, 140, 1), dtype=float32, numpy=\n",
       "array([[[1.4991663 ],\n",
       "        [1.4991663 ],\n",
       "        [1.4616871 ],\n",
       "        ...,\n",
       "        [0.41227072],\n",
       "        [0.41227072],\n",
       "        [0.41227072]],\n",
       "\n",
       "       [[1.4991663 ],\n",
       "        [1.4991663 ],\n",
       "        [1.4616871 ],\n",
       "        ...,\n",
       "        [0.41227072],\n",
       "        [0.41227072],\n",
       "        [0.41227072]],\n",
       "\n",
       "       [[1.4616871 ],\n",
       "        [1.4616871 ],\n",
       "        [1.4991663 ],\n",
       "        ...,\n",
       "        [0.3373124 ],\n",
       "        [0.3373124 ],\n",
       "        [0.3373124 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.0494163 ],\n",
       "        [1.0494163 ],\n",
       "        [1.0119373 ],\n",
       "        ...,\n",
       "        [0.11243746],\n",
       "        [0.11243746],\n",
       "        [0.07495831]],\n",
       "\n",
       "       [[1.0494163 ],\n",
       "        [1.0494163 ],\n",
       "        [1.0119373 ],\n",
       "        ...,\n",
       "        [0.11243746],\n",
       "        [0.07495831],\n",
       "        [0.07495831]],\n",
       "\n",
       "       [[1.0494163 ],\n",
       "        [1.0494163 ],\n",
       "        [1.0119373 ],\n",
       "        ...,\n",
       "        [0.07495831],\n",
       "        [0.07495831],\n",
       "        [0.03747915]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'whole the frame: {frames.shape}') # 75 frames, each frame is 46x140x1\n",
    "frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:36.054836Z",
     "iopub.status.busy": "2024-12-12T06:46:36.054318Z",
     "iopub.status.idle": "2024-12-12T06:46:37.084638Z",
     "shell.execute_reply": "2024-12-12T06:46:37.083688Z",
     "shell.execute_reply.started": "2024-12-12T06:46:36.054770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the alingments of the one video: [ 2  9 14 39  2 12 21  5 39  1 20 39  6 39 20 23 15 39 14 15 23]\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7eac63db5570>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'This is the alingments of the one video: {alignments}')\n",
    "print(' ')\n",
    "tf.strings.reduce_join([bytes.decode(i) for i in num_to_char(alignments.numpy()).numpy()])\n",
    "plt.imshow(frames[74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:37.086663Z",
     "iopub.status.busy": "2024-12-12T06:46:37.086197Z",
     "iopub.status.idle": "2024-12-12T06:46:37.143146Z",
     "shell.execute_reply": "2024-12-12T06:46:37.141975Z",
     "shell.execute_reply.started": "2024-12-12T06:46:37.086598Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'bin green at n six please', shape=(), dtype=string)\n",
      "tf.Tensor(b'bin red with t four now', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# # Lets check above videos we got from data pipelines with alginments\n",
    "print(tf.strings.reduce_join([num_to_char(word) for word in sample[1][0]]))\n",
    "print(tf.strings.reduce_join([num_to_char(word) for word in sample[1][1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:37.146178Z",
     "iopub.status.busy": "2024-12-12T06:46:37.145869Z",
     "iopub.status.idle": "2024-12-12T06:46:37.158481Z",
     "shell.execute_reply": "2024-12-12T06:46:37.157569Z",
     "shell.execute_reply.started": "2024-12-12T06:46:37.146151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPool3D, TimeDistributed, Reshape, Bidirectional, LSTM, Dropout, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:37.160128Z",
     "iopub.status.busy": "2024-12-12T06:46:37.159748Z",
     "iopub.status.idle": "2024-12-12T06:46:38.773150Z",
     "shell.execute_reply": "2024-12-12T06:46:38.771986Z",
     "shell.execute_reply.started": "2024-12-12T06:46:37.160077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a video shape: (2, 75, 46, 140, 1)\n",
      "This is a alignment shape: (2, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f'This is a video shape: {data.as_numpy_iterator().next()[0].shape}') #   data.as_numpy_iterator().next()[0][0].shape\n",
    "print(f'This is a alignment shape: {data.as_numpy_iterator().next()[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:38.774953Z",
     "iopub.status.busy": "2024-12-12T06:46:38.774601Z",
     "iopub.status.idle": "2024-12-12T06:46:38.781555Z",
     "shell.execute_reply": "2024-12-12T06:46:38.780325Z",
     "shell.execute_reply.started": "2024-12-12T06:46:38.774923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=tf.int64)\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=tf.int64)\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=tf.int64)\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=tf.int64)\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=tf.int64)\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:38.784007Z",
     "iopub.status.busy": "2024-12-12T06:46:38.783641Z",
     "iopub.status.idle": "2024-12-12T06:46:38.797704Z",
     "shell.execute_reply": "2024-12-12T06:46:38.796640Z",
     "shell.execute_reply.started": "2024-12-12T06:46:38.783968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ProductExampleCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = model.predict(data[0])\n",
    "        decode = tf.keras.backend.ctc_decode(yhat, [75, 75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):\n",
    "            print('Original: ', tf.strings.reduce_join([num_to_char(word) for word in data[1][x]]).numpy().decode('utf-8'))\n",
    "            print('Predicted: ', tf.strings.reduce_join([num_to_char(word) for word in decode[x]]).numpy().decode('utf-8'))\n",
    "\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:40.672287Z",
     "iopub.status.busy": "2024-12-12T06:46:40.671463Z",
     "iopub.status.idle": "2024-12-12T06:46:42.497322Z",
     "shell.execute_reply": "2024-12-12T06:46:42.496288Z",
     "shell.execute_reply.started": "2024-12-12T06:46:40.672252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noobs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(256, 3, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(75, 3, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(TimeDistributed(Reshape((-1,))))\n",
    "\n",
    "# model.add(Bidirectional(LSTM(128, kernel_initializer='orthogonal', return_sequences=True)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Bidirectional(LSTM(128, kernel_initializer='orthogonal', return_sequences=True)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(char_to_num.vocabulary_size()+1,  kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First Conv3D block\n",
    "model.add(Conv3D(128, 3, input_shape=(75, 46, 140, 1), padding='same'))\n",
    "model.add(BatchNormalization())  # Added BatchNormalization\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# Second Conv3D block\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())  # Added BatchNormalization\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# Third Conv3D block\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(BatchNormalization())  # Added BatchNormalization\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# Flatten the spatial dimensions while preserving the time dimension\n",
    "model.add(TimeDistributed(Reshape((-1,))))\n",
    "\n",
    "# First LSTM block\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Second LSTM block\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Fully connected output layer\n",
    "model.add(Dense(char_to_num.vocabulary_size() + 1, kernel_initializer='he_normal', activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:42.499806Z",
     "iopub.status.busy": "2024-12-12T06:46:42.499296Z",
     "iopub.status.idle": "2024-12-12T06:46:42.541096Z",
     "shell.execute_reply": "2024-12-12T06:46:42.539983Z",
     "shell.execute_reply.started": "2024-12-12T06:46:42.499741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>,    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>,    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>,     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>,     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">518,475</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6375</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,660,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,537</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m140\u001b[0m,    │         \u001b[38;5;34m3,584\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m140\u001b[0m,    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m140\u001b[0m,    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m70\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m70\u001b[0m,     │       \u001b[38;5;34m884,992\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m256\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m70\u001b[0m,     │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m70\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m256\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m35\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m256\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m75\u001b[0m) │       \u001b[38;5;34m518,475\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m75\u001b[0m) │           \u001b[38;5;34m300\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m75\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m75\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m6375\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m6,660,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m41\u001b[0m)         │        \u001b[38;5;34m10,537\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,473,760</span> (32.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,473,760\u001b[0m (32.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,472,842</span> (32.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,472,842\u001b[0m (32.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">918</span> (3.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m918\u001b[0m (3.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:42.701477Z",
     "iopub.status.busy": "2024-12-12T06:46:42.700520Z",
     "iopub.status.idle": "2024-12-12T06:46:49.222040Z",
     "shell.execute_reply": "2024-12-12T06:46:49.221162Z",
     "shell.execute_reply.started": "2024-12-12T06:46:42.701426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:49.224901Z",
     "iopub.status.busy": "2024-12-12T06:46:49.224179Z",
     "iopub.status.idle": "2024-12-12T06:46:49.231720Z",
     "shell.execute_reply": "2024-12-12T06:46:49.230687Z",
     "shell.execute_reply.started": "2024-12-12T06:46:49.224855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 41)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:49.233195Z",
     "iopub.status.busy": "2024-12-12T06:46:49.232897Z",
     "iopub.status.idle": "2024-12-12T06:46:49.309943Z",
     "shell.execute_reply": "2024-12-12T06:46:49.308956Z",
     "shell.execute_reply.started": "2024-12-12T06:46:49.233167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b\"mmmt'''twwwwwwwwwwwwwwwtttttwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww99\">"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join([num_to_char(word) for word in tf.argmax(yhat[0], axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:49.312046Z",
     "iopub.status.busy": "2024-12-12T06:46:49.311729Z",
     "iopub.status.idle": "2024-12-12T06:46:49.316517Z",
     "shell.execute_reply": "2024-12-12T06:46:49.315511Z",
     "shell.execute_reply.started": "2024-12-12T06:46:49.312015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:49.318294Z",
     "iopub.status.busy": "2024-12-12T06:46:49.317971Z",
     "iopub.status.idle": "2024-12-12T06:46:49.329875Z",
     "shell.execute_reply": "2024-12-12T06:46:49.328918Z",
     "shell.execute_reply.started": "2024-12-12T06:46:49.318266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_weights.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:50.161453Z",
     "iopub.status.busy": "2024-12-12T06:46:50.160719Z",
     "iopub.status.idle": "2024-12-12T06:46:50.179296Z",
     "shell.execute_reply": "2024-12-12T06:46:50.178346Z",
     "shell.execute_reply.started": "2024-12-12T06:46:50.161417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "example_callback = ProductExampleCallback(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:46:50.580233Z",
     "iopub.status.busy": "2024-12-12T06:46:50.579499Z",
     "iopub.status.idle": "2024-12-12T06:46:50.593829Z",
     "shell.execute_reply": "2024-12-12T06:46:50.592835Z",
     "shell.execute_reply.started": "2024-12-12T06:46:50.580195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=CTCLoss, optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:48:58.200999Z",
     "iopub.status.busy": "2024-12-12T06:48:58.200525Z",
     "iopub.status.idle": "2024-12-12T06:49:05.455927Z",
     "shell.execute_reply": "2024-12-12T06:49:05.454851Z",
     "shell.execute_reply.started": "2024-12-12T06:48:58.200964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Xl2VrkQFWpn2O612qyDinN8L_kyFzv08\n",
      "To: d:\\Projects\\DeepLearning\\LipApp\\new_best_weights2.weights.h5\n",
      "100%|██████████| 102M/102M [00:17<00:00, 5.77MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'new_best_weights2.weights.h5'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://drive.google.com/file/d/1gSbYQ67ihBZw6cc-_ARcSeNcJPW14j0o/view?usp=sharing\n",
    "# # Replace the ID with the actual file ID from your Google Drive link\n",
    "# https://drive.google.com/file/d/1Xl2VrkQFWpn2O612qyDinN8L_kyFzv08/view?usp=sharing\n",
    "# https://drive.google.com/file/d/1oiGL9pDYX4-AdOVuypJEsL9MgXTABjko/view?usp=sharing\n",
    "file_id = '1Xl2VrkQFWpn2O612qyDinN8L_kyFzv08'\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'new_best_weights2.weights.h5', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:49:39.117120Z",
     "iopub.status.busy": "2024-12-12T06:49:39.116734Z",
     "iopub.status.idle": "2024-12-12T06:49:39.211160Z",
     "shell.execute_reply": "2024-12-12T06:49:39.210022Z",
     "shell.execute_reply.started": "2024-12-12T06:49:39.117090Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noobs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 54 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('new_best_weights2.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:51:59.947750Z",
     "iopub.status.busy": "2024-12-12T06:51:59.947313Z",
     "iopub.status.idle": "2024-12-12T06:51:59.959022Z",
     "shell.execute_reply": "2024-12-12T06:51:59.957799Z",
     "shell.execute_reply.started": "2024-12-12T06:51:59.947715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model evaulate\n",
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:58:37.684377Z",
     "iopub.status.busy": "2024-12-12T06:58:37.683329Z",
     "iopub.status.idle": "2024-12-12T06:58:37.691148Z",
     "shell.execute_reply": "2024-12-12T06:58:37.690027Z",
     "shell.execute_reply.started": "2024-12-12T06:58:37.684337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T06:58:48.750896Z",
     "iopub.status.busy": "2024-12-12T06:58:48.750458Z",
     "iopub.status.idle": "2024-12-12T06:58:55.913401Z",
     "shell.execute_reply": "2024-12-12T06:58:55.912075Z",
     "shell.execute_reply.started": "2024-12-12T06:58:48.750860Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:25.134364Z",
     "iopub.status.busy": "2024-12-12T07:09:25.133961Z",
     "iopub.status.idle": "2024-12-12T07:09:25.145412Z",
     "shell.execute_reply": "2024-12-12T07:09:25.144297Z",
     "shell.execute_reply.started": "2024-12-12T07:09:25.134330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "This is original text: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin green in n three againbin white by n two now'>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('='*100)\n",
    "print('This is original text: ')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:13:20.423427Z",
     "iopub.status.busy": "2024-12-12T07:13:20.422996Z",
     "iopub.status.idle": "2024-12-12T07:13:20.433184Z",
     "shell.execute_reply": "2024-12-12T07:13:20.432171Z",
     "shell.execute_reply.started": "2024-12-12T07:13:20.423393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, [75, 75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:13:21.139338Z",
     "iopub.status.busy": "2024-12-12T07:13:21.138958Z",
     "iopub.status.idle": "2024-12-12T07:13:21.229861Z",
     "shell.execute_reply": "2024-12-12T07:13:21.228681Z",
     "shell.execute_reply.started": "2024-12-12T07:13:21.139305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "This is prediction: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin green in n three again'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'bin white by n two now'>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"* 100)\n",
    "print('This is prediction: ')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test On Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:17:01.119786Z",
     "iopub.status.busy": "2024-12-12T07:17:01.118965Z",
     "iopub.status.idle": "2024-12-12T07:17:01.418119Z",
     "shell.execute_reply": "2024-12-12T07:17:01.417148Z",
     "shell.execute_reply.started": "2024-12-12T07:17:01.119749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample2 = load_data(tf.convert_to_tensor('data/s1/bbaz4n.mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:17:01.510095Z",
     "iopub.status.busy": "2024-12-12T07:17:01.509670Z",
     "iopub.status.idle": "2024-12-12T07:17:01.542821Z",
     "shell.execute_reply": "2024-12-12T07:17:01.541870Z",
     "shell.execute_reply.started": "2024-12-12T07:17:01.510061Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at z four now'>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample2[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:17:01.947553Z",
     "iopub.status.busy": "2024-12-12T07:17:01.946867Z",
     "iopub.status.idle": "2024-12-12T07:17:07.119578Z",
     "shell.execute_reply": "2024-12-12T07:17:07.118386Z",
     "shell.execute_reply.started": "2024-12-12T07:17:01.947507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(tf.expand_dims(sample2[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:17:07.121846Z",
     "iopub.status.busy": "2024-12-12T07:17:07.121465Z",
     "iopub.status.idle": "2024-12-12T07:17:07.129700Z",
     "shell.execute_reply": "2024-12-12T07:17:07.128854Z",
     "shell.execute_reply.started": "2024-12-12T07:17:07.121806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:17:07.131242Z",
     "iopub.status.busy": "2024-12-12T07:17:07.130925Z",
     "iopub.status.idle": "2024-12-12T07:17:07.191214Z",
     "shell.execute_reply": "2024-12-12T07:17:07.190151Z",
     "shell.execute_reply.started": "2024-12-12T07:17:07.131214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at z four now'>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T05:00:10.465975Z",
     "iopub.status.busy": "2024-12-11T05:00:10.465543Z",
     "iopub.status.idle": "2024-12-11T09:42:56.105911Z",
     "shell.execute_reply": "2024-12-11T09:42:56.104647Z",
     "shell.execute_reply.started": "2024-12-11T05:00:10.465923Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150\n",
      "\u001b[1m160/450\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 742ms/step - loss: 5.8616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addb408ea00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addb408ea00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - loss: 5.8287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd00a5580] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd00a5580] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 101: val_loss did not improve from 2.98227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "Original:  place blue by c five soon\n",
      "Predicted:  place blue by c five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  lay red at k nine again\n",
      "Predicted:  lay red at v nine again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 5.8283 - val_loss: 3.0008 - learning_rate: 1.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m268/450\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 744ms/step - loss: 5.6942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade6c0a0a80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade6c0a0a80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 5.7174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf280b7d00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf280b7d00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102: val_loss improved from 2.98227 to 2.86376, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Original:  lay blue in x seven again\n",
      "Predicted:  lay blue in x seven again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  bin blue with m six please\n",
      "Predicted:  bin blue with h six please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 1s/step - loss: 5.7173 - val_loss: 2.8638 - learning_rate: 1.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m139/450\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 746ms/step - loss: 5.5231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd876d180] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd876d180] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 5.4480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade100abd40] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade100abd40] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103: val_loss did not improve from 2.86376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Original:  bin blue by f nine again\n",
      "Predicted:  bin blue by f nine again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  lay red in q six now\n",
      "Predicted:  lay red in k six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 5.4481 - val_loss: 3.3282 - learning_rate: 1.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m182/450\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 746ms/step - loss: 4.9251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addb406d0c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addb406d0c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - loss: 5.1105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addc9916b40] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addc9916b40] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104: val_loss did not improve from 2.86376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Original:  bin red by m six now\n",
      "Predicted:  bin red by l six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place white in c eight now\n",
      "Predicted:  place white in c eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 1s/step - loss: 5.1109 - val_loss: 3.3975 - learning_rate: 1.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m276/450\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 746ms/step - loss: 5.0768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade58082240] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade58082240] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 5.1221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf34010c00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf34010c00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 105: val_loss improved from 2.86376 to 2.50140, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "Original:  lay red in q seven soon\n",
      "Predicted:  lay red in d seven son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  lay blue at d nine again\n",
      "Predicted:  lay blue at d nine again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 5.1222 - val_loss: 2.5014 - learning_rate: 1.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m249/450\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 744ms/step - loss: 5.1239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd409f680] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd409f680] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - loss: 5.2330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade08036e80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade08036e80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106: val_loss did not improve from 2.50140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Original:  lay red by r seven again\n",
      "Predicted:  lay red by s seven again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  set green in o nine again\n",
      "Predicted:  set gren in o nine again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 1s/step - loss: 5.2331 - val_loss: 2.5599 - learning_rate: 1.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m161/450\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 746ms/step - loss: 5.1780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x5aaefd4d8c00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x5aaefd4d8c00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - loss: 5.3876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addc403f680] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addc403f680] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 107: val_loss did not improve from 2.50140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "Original:  set blue at t seven soon\n",
      "Predicted:  set blue at t seven son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place blue by c four now\n",
      "Predicted:  place blue by c four now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 1s/step - loss: 5.3879 - val_loss: 2.7255 - learning_rate: 1.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - loss: 5.0255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf2c436300] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf2c436300] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108: val_loss did not improve from 2.50140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "Original:  place white with e three again\n",
      "Predicted:  place white with thre again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  bin green with i one again\n",
      "Predicted:  bin gren with i one again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 1s/step - loss: 5.0259 - val_loss: 2.6725 - learning_rate: 1.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m397/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m39s\u001b[0m 747ms/step - loss: 5.2234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd4177800] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd4177800] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - loss: 5.2715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addf00a4a40] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addf00a4a40] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 109: val_loss did not improve from 2.50140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "Original:  lay green in r eight now\n",
      "Predicted:  lay gren in r eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  set green in o seven soon\n",
      "Predicted:  set gren in o seven son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 1s/step - loss: 5.2724 - val_loss: 3.6413 - learning_rate: 1.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m303/450\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 749ms/step - loss: 5.2102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf4007da80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf4007da80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - loss: 5.3072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd00e6480] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd00e6480] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110: val_loss improved from 2.50140 to 2.34379, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Original:  bin blue in l four please\n",
      "Predicted:  bin blue in z four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  lay white in y six now\n",
      "Predicted:  lay white in o six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 1s/step - loss: 5.3078 - val_loss: 2.3438 - learning_rate: 1.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m109/450\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:14\u001b[0m 746ms/step - loss: 5.0432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade20046780] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade20046780] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - loss: 4.8765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf280ef7c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf280ef7c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 111: val_loss did not improve from 2.34379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Original:  lay red in k four please\n",
      "Predicted:  lay red in k four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place red by q zero please\n",
      "Predicted:  place red by y zero please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 4.8766 - val_loss: 2.5431 - learning_rate: 1.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m168/450\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 748ms/step - loss: 4.6419"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd40389c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd40389c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - loss: 4.7250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addf00dd240] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addf00dd240] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112: val_loss did not improve from 2.34379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Original:  lay blue sp at q five soon\n",
      "Predicted:  lay blue at j five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  bin red at m five again\n",
      "Predicted:  bin red at f five again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 1s/step - loss: 4.7251 - val_loss: 2.5058 - learning_rate: 1.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m 90/450\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:27\u001b[0m 744ms/step - loss: 4.1824"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addb425bf80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addb425bf80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - loss: 4.4225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd0263a00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd0263a00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 113: val_loss did not improve from 2.34379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Original:  set red in a six now\n",
      "Predicted:  set red in i six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  lay blue at k zero now\n",
      "Predicted:  lay blue at z zero now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 1s/step - loss: 4.4228 - val_loss: 2.6798 - learning_rate: 1.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m101/450\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:19\u001b[0m 743ms/step - loss: 4.3504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade181240c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade181240c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - loss: 4.7038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf2c4080c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf2c4080c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 114: val_loss did not improve from 2.34379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Original:  place green with l two please\n",
      "Predicted:  place gren with p two please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  bin white in t zero please\n",
      "Predicted:  bin white in t zero please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 1s/step - loss: 4.7043 - val_loss: 2.5582 - learning_rate: 1.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m 69/450\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 753ms/step - loss: 4.3113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd4037fc0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd4037fc0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - loss: 4.4802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade140a9800] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade140a9800] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 115: val_loss did not improve from 2.34379\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Original:  place white with q eight now\n",
      "Predicted:  place white with h eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place green at e one again\n",
      "Predicted:  place gren at s one again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 1s/step - loss: 4.4803 - val_loss: 3.2748 - learning_rate: 1.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m189/450\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:17\u001b[0m 757ms/step - loss: 5.3183"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addb40dd180] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addb40dd180] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - loss: 4.8275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd01e4a40] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd01e4a40] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116: val_loss improved from 2.34379 to 1.81755, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Original:  lay blue with e four now\n",
      "Predicted:  lay blue with e four now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place blue with p nine again\n",
      "Predicted:  place blue with p nine again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 1s/step - loss: 4.8262 - val_loss: 1.8175 - learning_rate: 5.0000e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m 13/450\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:33\u001b[0m 764ms/step - loss: 3.3731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade200470c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade200470c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - loss: 3.8875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf30064080] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf30064080] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 117: val_loss improved from 1.81755 to 1.53292, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Original:  set red at h four now\n",
      "Predicted:  set red at t four now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place red at j three again\n",
      "Predicted:  place red at j thre again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 1s/step - loss: 3.8875 - val_loss: 1.5329 - learning_rate: 5.0000e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m244/450\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 750ms/step - loss: 3.6499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd8778bc0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd8778bc0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - loss: 3.6748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade1008b740] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade1008b740] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 118: val_loss did not improve from 1.53292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Original:  place green by k eight please\n",
      "Predicted:  place gren by k eight please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place red at x one again\n",
      "Predicted:  place red at x one again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 1s/step - loss: 3.6748 - val_loss: 1.9705 - learning_rate: 5.0000e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m349/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 750ms/step - loss: 3.6216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x5aaef811a200] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x5aaef811a200] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - loss: 3.6143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addc9a7d800] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addc9a7d800] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 119: val_loss did not improve from 1.53292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Original:  place white in j five again\n",
      "Predicted:  place white in d five again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place green at q eight please\n",
      "Predicted:  place gren at q eight please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 1s/step - loss: 3.6142 - val_loss: 1.6988 - learning_rate: 5.0000e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m249/450\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 744ms/step - loss: 3.1949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade58196400] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade58196400] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - loss: 3.3013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf30020e80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf30020e80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120: val_loss improved from 1.53292 to 1.43750, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Original:  bin blue at s three again\n",
      "Predicted:  bin blue at s thre again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place white with e two please\n",
      "Predicted:  place white with e two please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 3.3015 - val_loss: 1.4375 - learning_rate: 5.0000e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m315/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 746ms/step - loss: 3.4262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addcc023b00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addcc023b00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - loss: 3.4248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addf009f440] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addf009f440] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 121: val_loss did not improve from 1.43750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "Original:  bin white in m four now\n",
      "Predicted:  bin white in f four now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place red with d four now\n",
      "Predicted:  place red with d four now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 1s/step - loss: 3.4247 - val_loss: 1.5619 - learning_rate: 5.0000e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m175/450\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:24\u001b[0m 744ms/step - loss: 3.4181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x5aaeeff04940] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x5aaeeff04940] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - loss: 3.4351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addbc050640] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addbc050640] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 122: val_loss did not improve from 1.43750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "Original:  lay blue at q seven again\n",
      "Predicted:  lay blue at d seven again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  place white with k five soon\n",
      "Predicted:  place white with k five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 3.4351 - val_loss: 1.5482 - learning_rate: 5.0000e-05\n",
      "Epoch 123/150\n",
      "\u001b[1m 28/450\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 746ms/step - loss: 3.0078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade20029680] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade20029680] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 3.3804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf280ce500] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf280ce500] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 123: val_loss did not improve from 1.43750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Original:  set white at u nine soon\n",
      "Predicted:  set white at u nine son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  set white by i four now\n",
      "Predicted:  set white by i four now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 3.3804 - val_loss: 1.6389 - learning_rate: 5.0000e-05\n",
      "Epoch 124/150\n",
      "\u001b[1m219/450\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 747ms/step - loss: 3.5315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd8798780] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd8798780] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - loss: 3.4499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade1003a6c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade1003a6c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124: val_loss did not improve from 1.43750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Original:  place blue with j four please\n",
      "Predicted:  place blue with j four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  bin white at a one soon\n",
      "Predicted:  bin white at a one son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 1s/step - loss: 3.4497 - val_loss: 1.4631 - learning_rate: 5.0000e-05\n",
      "Epoch 125/150\n",
      "\u001b[1m438/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 745ms/step - loss: 3.5318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf40531400] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf40531400] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 3.5292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd00311c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd00311c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 125: val_loss improved from 1.43750 to 1.38357, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Original:  lay red with z four please\n",
      "Predicted:  lay red with z four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  bin green at a six now\n",
      "Predicted:  bin gren at a six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 3.5290 - val_loss: 1.3836 - learning_rate: 5.0000e-05\n",
      "Epoch 126/150\n",
      "\u001b[1m363/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:04\u001b[0m 742ms/step - loss: 3.3328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade5804cc00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade5804cc00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - loss: 3.3504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf280d5fc0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf280d5fc0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 126: val_loss did not improve from 1.38357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Original:  lay green by g zero please\n",
      "Predicted:  lay gren by g zero please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  lay red by l three again\n",
      "Predicted:  lay red by l thre again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 1s/step - loss: 3.3506 - val_loss: 1.5488 - learning_rate: 5.0000e-05\n",
      "Epoch 127/150\n",
      "\u001b[1m338/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 743ms/step - loss: 3.2491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addcc1b5a80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addcc1b5a80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - loss: 3.2544"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade08051b00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade08051b00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 127: val_loss did not improve from 1.38357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "Original:  lay red in k five again\n",
      "Predicted:  lay red in v five again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  bin red by g five again\n",
      "Predicted:  bin red by g five again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 1s/step - loss: 3.2545 - val_loss: 1.3920 - learning_rate: 5.0000e-05\n",
      "Epoch 128/150\n",
      "\u001b[1m 43/450\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:05\u001b[0m 751ms/step - loss: 3.0240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf404f3780] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf404f3780] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - loss: 3.3005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addbc028f00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addbc028f00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 128: val_loss did not improve from 1.38357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Original:  bin red with t four now\n",
      "Predicted:  bin red with t four now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  lay green at l nine soon\n",
      "Predicted:  lay gren at l nine son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 1s/step - loss: 3.3005 - val_loss: 1.4816 - learning_rate: 5.0000e-05\n",
      "Epoch 129/150\n",
      "\u001b[1m305/450\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 741ms/step - loss: 2.9286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade580280c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade580280c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - loss: 2.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7adf280b8e00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7adf280b8e00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 129: val_loss improved from 1.38357 to 1.31727, saving model to best_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Original:  set red by h eight now\n",
      "Predicted:  set red by h eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  set blue at n two now\n",
      "Predicted:  set blue at t two now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 1s/step - loss: 2.9502 - val_loss: 1.3173 - learning_rate: 5.0000e-05\n",
      "Epoch 130/150\n",
      "\u001b[1m157/450\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:38\u001b[0m 746ms/step - loss: 3.0306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd8890200] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd8890200] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 2.9966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7ade080e1000] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7ade080e1000] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130: val_loss did not improve from 1.31727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Original:  set white by v three soon\n",
      "Predicted:  set white by v thre son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  set green at c five again\n",
      "Predicted:  set gren at c five again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 1s/step - loss: 2.9965 - val_loss: 1.3583 - learning_rate: 5.0000e-05\n",
      "Epoch 131/150\n",
      "\u001b[1m 93/450\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:26\u001b[0m 748ms/step - loss: 3.2169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addb40d01c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addb40d01c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - loss: 3.0377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7addd00a72c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7addd00a72c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 131: val_loss did not improve from 1.31727\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Resume training from epoch 75\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Start from epoch 75\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m, in \u001b[0;36mProductExampleCallback.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     yhat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m     decode \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mctc_decode(yhat, [\u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m75\u001b[39m], greedy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Resume training from epoch 75\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=150,\n",
    "    initial_epoch=100,  # Start from epoch 75\n",
    "    callbacks=[checkpoint_callback, reduce_lr, early_stopping, example_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint_callback, reduce_lr, early_stopping, example_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
